
---

## 🧠 Key Learning Highlights

- Built robust ETL pipelines using PySpark
- Managed streaming and batch data efficiently
- Created Delta Live Tables and layered architecture (Bronze, Silver, Gold)
- Used Auto Loader for incremental ingest
- Created dashboards to visualize insights
- Orchestrated jobs for automated pipeline execution

---

## 📊 Dataset Source

- NYC Taxi & FHV Data: [https://www.kaggle.com/datasets/microize/newyork-yellow-taxi-trip-data-2020-201]  
- Sample data stored in `data/` folder or linked via DBFS.

---

## 🚀 How to Run

1. Open your Databricks workspace
2. Upload the notebooks from `/notebooks`
3. Attach to your cluster and run each notebook in sequence
4. Optional: Run `pip install -r requirements.txt` in local environment

---

## 📸 Sample Outputs

You can view pipeline screenshots and visual outputs in the [`assets/`](./assets/) folder.

---

## 🗺️ Future Additions

- ML model on taxi trip duration prediction
- Integration with MLflow
- Connecting pipelines with AWS S3 / Azure

---

## 🙋‍♀️ About Me

**Anusha Garg**  
AI/ML Engineer | Data Engineering Enthusiast | Full-Stack Developer  
💼 [LinkedIn](https://www.linkedin.com/in/anusha-garg) | 📧 anushagarg2003@gmail.com

---

## ⭐ Star This Repo

If you find this project helpful, please ⭐ the repo and share your thoughts!
