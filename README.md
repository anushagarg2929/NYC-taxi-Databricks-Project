
---

## ğŸ§  Key Learning Highlights

- Built robust ETL pipelines using PySpark
- Managed streaming and batch data efficiently
- Created Delta Live Tables and layered architecture (Bronze, Silver, Gold)
- Used Auto Loader for incremental ingest
- Created dashboards to visualize insights
- Orchestrated jobs for automated pipeline execution

---

## ğŸ“Š Dataset Source

- NYC Taxi & FHV Data: [https://www.kaggle.com/datasets/microize/newyork-yellow-taxi-trip-data-2020-201]  
- Sample data stored in `data/` folder or linked via DBFS.

---

## ğŸš€ How to Run

1. Open your Databricks workspace
2. Upload the notebooks from `/notebooks`
3. Attach to your cluster and run each notebook in sequence
4. Optional: Run `pip install -r requirements.txt` in local environment

---

## ğŸ“¸ Sample Outputs

You can view pipeline screenshots and visual outputs in the [`assets/`](./assets/) folder.

---

## ğŸ—ºï¸ Future Additions

- ML model on taxi trip duration prediction
- Integration with MLflow
- Connecting pipelines with AWS S3 / Azure

---

## ğŸ™‹â€â™€ï¸ About Me

**Anusha Garg**  
AI/ML Engineer | Data Engineering Enthusiast | Full-Stack Developer  
ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/anusha-garg) | ğŸ“§ anushagarg2003@gmail.com

---

## â­ Star This Repo

If you find this project helpful, please â­ the repo and share your thoughts!
